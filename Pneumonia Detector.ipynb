{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "095426ed-1c0a-4b16-b2ed-25eb6b46e564",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\rajveer gupta\\anaconda3\\lib\\site-packages (2.16.2)\n",
      "Requirement already satisfied: tensorflow-intel==2.16.2 in c:\\users\\rajveer gupta\\anaconda3\\lib\\site-packages (from tensorflow) (2.16.2)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\rajveer gupta\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow) (2.3.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\rajveer gupta\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in c:\\users\\rajveer gupta\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\rajveer gupta\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\rajveer gupta\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in c:\\users\\rajveer gupta\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow) (3.14.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\rajveer gupta\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes~=0.3.1 in c:\\users\\rajveer gupta\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow) (0.3.2)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\rajveer gupta\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\rajveer gupta\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow) (24.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\rajveer gupta\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow) (4.25.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\rajveer gupta\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\rajveer gupta\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow) (75.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\rajveer gupta\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\rajveer gupta\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow) (3.1.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\rajveer gupta\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow) (4.11.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\rajveer gupta\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\rajveer gupta\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow) (1.73.0)\n",
      "Requirement already satisfied: tensorboard<2.17,>=2.16 in c:\\users\\rajveer gupta\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow) (2.16.2)\n",
      "Requirement already satisfied: keras>=3.0.0 in c:\\users\\rajveer gupta\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow) (3.10.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.26.0 in c:\\users\\rajveer gupta\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow) (1.26.4)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\rajveer gupta\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.16.2->tensorflow) (0.44.0)\n",
      "Requirement already satisfied: rich in c:\\users\\rajveer gupta\\anaconda3\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.2->tensorflow) (14.0.0)\n",
      "Requirement already satisfied: namex in c:\\users\\rajveer gupta\\anaconda3\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.2->tensorflow) (0.1.0)\n",
      "Requirement already satisfied: optree in c:\\users\\rajveer gupta\\anaconda3\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.2->tensorflow) (0.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\rajveer gupta\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.2->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\rajveer gupta\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.2->tensorflow) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\rajveer gupta\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.2->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\rajveer gupta\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.2->tensorflow) (2025.6.15)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\rajveer gupta\\anaconda3\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.2->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\rajveer gupta\\anaconda3\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.2->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\rajveer gupta\\anaconda3\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.2->tensorflow) (3.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\rajveer gupta\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow-intel==2.16.2->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\rajveer gupta\\anaconda3\\lib\\site-packages (from rich->keras>=3.0.0->tensorflow-intel==2.16.2->tensorflow) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\rajveer gupta\\anaconda3\\lib\\site-packages (from rich->keras>=3.0.0->tensorflow-intel==2.16.2->tensorflow) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\rajveer gupta\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow-intel==2.16.2->tensorflow) (0.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4fe7a106-f3b0-4119-a71f-b0d2f4164c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "from tensorflow.keras.layers import Layer\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "462de672-f814-4015-8827-c9f624e47741",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    horizontal_flip=True,\n",
    "    rotation_range=15,\n",
    "    zoom_range=0.1,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.1,\n",
    "    fill_mode='nearest'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eeb9b667-9227-42b2-9345-34198c73a5f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datagen=ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce5c3788-b650-4b3b-af1e-d6dde1121d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_datagen=ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a494b062-4178-4528-83fa-63b7deaf1db0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Extraction done!\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "\n",
    "zip_path = \"Chest X-ray Dataset Kaggle.zip\"\n",
    "extract_path = \"Chest X-ray Dataset Kaggle\"\n",
    "\n",
    "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(extract_path)\n",
    "\n",
    "print(\"✅ Extraction done!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "160d3659-afcb-4991-9630-f18bb0eab1b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5216 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(\n",
    "    \"Chest X-ray Dataset Kaggle/chest_xray/train\",\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='binary',\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e775bc95-c093-4bb4-bd79-ecb95cf05a91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 625 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "test_generator=test_datagen.flow_from_directory(\n",
    "    \"Chest X-ray Dataset Kaggle/chest_xray/test\",\n",
    "    target_size=(224,224),\n",
    "    batch_size=32,\n",
    "    class_mode='binary',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1015d9cd-4534-4f45-a1ef-c128dd4a5e51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 16 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "valid_generator=valid_datagen.flow_from_directory(\n",
    "    \"Chest X-ray Dataset kaggle/chest_xray/val\",\n",
    "    target_size=(224,224),\n",
    "    batch_size=32,\n",
    "    class_mode='binary',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f235af80-be62-41b7-9aca-301dd8de5882",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Layer, Dense\n",
    "\n",
    "class MultiHeadSelfAttention(Layer):\n",
    "    def __init__(self, embed_dim, num_heads=8, **kwargs):\n",
    "        super(MultiHeadSelfAttention, self).__init__(**kwargs)\n",
    "        self.embed_dim = embed_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.query_dense = Dense(embed_dim)\n",
    "        self.key_dense = Dense(embed_dim)\n",
    "        self.value_dense = Dense(embed_dim)\n",
    "        self.combine_heads = Dense(embed_dim)\n",
    "        self.projection_dim = self.embed_dim // self.num_heads\n",
    "\n",
    "    def attention(self, query, key, value):\n",
    "        score = tf.matmul(query, key, transpose_b=True)\n",
    "        dim_key = tf.cast(tf.shape(key)[-1], tf.float32)\n",
    "        scaled_score = score / tf.math.sqrt(dim_key)\n",
    "        weights = tf.nn.softmax(scaled_score, axis=-1)\n",
    "        output = tf.matmul(weights, value)\n",
    "        return output, weights\n",
    "\n",
    "    def split_heads(self, x, batch_size):\n",
    "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.projection_dim))\n",
    "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "\n",
    "    def call(self, inputs):\n",
    "        seq_len = tf.shape(inputs)[1]\n",
    "        batch_size = tf.shape(inputs)[0]\n",
    "        query = self.query_dense(inputs)\n",
    "        key = self.key_dense(inputs)\n",
    "        value = self.value_dense(inputs)\n",
    "        query = self.split_heads(query, batch_size)\n",
    "        key = self.split_heads(key, batch_size)\n",
    "        value = self.split_heads(value, batch_size)\n",
    "        attention, _ = self.attention(query, key, value)\n",
    "        attention = tf.reshape(attention, (batch_size, seq_len, self.embed_dim))\n",
    "        output = self.combine_heads(attention)\n",
    "        return output\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            \"embed_dim\": self.embed_dim,\n",
    "            \"num_heads\": self.num_heads\n",
    "        })\n",
    "        return config\n",
    "\n",
    "    @classmethod\n",
    "    def from_config(cls, config):\n",
    "        return cls(**config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a3d328af-b8d7-46cf-b182-ad665962e82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import LayerNormalization, Dropout, Layer, Dense\n",
    "from keras.models import Sequential\n",
    "\n",
    "class TransformerBlock(Layer):\n",
    "    def __init__(self, embed_dim, num_heads, ffn_dim, **kwargs):\n",
    "        super(TransformerBlock, self).__init__(**kwargs)\n",
    "        self.embed_dim = embed_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.ffn_dim = ffn_dim\n",
    "\n",
    "        self.att = MultiHeadSelfAttention(embed_dim, num_heads)\n",
    "        self.ffn = Sequential([\n",
    "            Dense(ffn_dim, activation='relu'),\n",
    "            Dense(embed_dim)\n",
    "        ])\n",
    "        self.layernorm1 = LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = Dropout(rate=0.01)\n",
    "        self.dropout2 = Dropout(rate=0.01)\n",
    "\n",
    "    def call(self, inputs, training):\n",
    "        attention = self.att(inputs)\n",
    "        attention = self.dropout1(attention, training=training)\n",
    "        out1 = self.layernorm1(inputs + attention)\n",
    "        out2 = self.ffn(out1)\n",
    "        out2 = self.dropout2(out2, training=training)\n",
    "        return self.layernorm2(out1 + out2)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            \"embed_dim\": self.embed_dim,\n",
    "            \"num_heads\": self.num_heads,\n",
    "            \"ffn_dim\": self.ffn_dim\n",
    "        })\n",
    "        return config\n",
    "\n",
    "    @classmethod\n",
    "    def from_config(cls, config):\n",
    "        return cls(**config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ddf669ed-3c04-43da-84e6-f9f5e9f77fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Layer, Dense\n",
    "\n",
    "class PatchEmbedding(Layer):\n",
    "    def __init__(self, num_patches, embed_dim, **kwargs):\n",
    "        super(PatchEmbedding, self).__init__(**kwargs)\n",
    "        self.num_patches = num_patches\n",
    "        self.embed_dim = embed_dim\n",
    "        self.projection = Dense(embed_dim)\n",
    "\n",
    "    def call(self, patches):\n",
    "        return self.projection(patches)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            \"num_patches\": self.num_patches,\n",
    "            \"embed_dim\": self.embed_dim\n",
    "        })\n",
    "        return config\n",
    "\n",
    "    @classmethod\n",
    "    def from_config(cls, config):\n",
    "        return cls(**config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "58bd2c8e-c0fd-4323-a991-64e39890b1e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Flatten, Dropout\n",
    "from tensorflow.keras.layers import GlobalAveragePooling1D, Conv2D, MaxPooling2D\n",
    "from keras.models import Model\n",
    "import tensorflow as tf\n",
    "\n",
    "class VisionImageTransformer(Model):\n",
    "    def __init__(self, num_patches, num_heads, embed_dim, ffn_dim, num_layers, num_classes, **kwargs):\n",
    "        super(VisionImageTransformer, self).__init__(**kwargs)\n",
    "        self.num_patches = num_patches\n",
    "        self.num_heads = num_heads\n",
    "        self.embed_dim = embed_dim\n",
    "        self.ffn_dim = ffn_dim\n",
    "        self.num_layers = num_layers\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        self.patch_embed = PatchEmbedding(num_patches, embed_dim)\n",
    "        self.transformer_layers = [\n",
    "            TransformerBlock(embed_dim, num_heads, ffn_dim)\n",
    "            for _ in range(num_layers)\n",
    "        ]\n",
    "\n",
    "        self.flatten = Flatten()\n",
    "        self.conv2D_layer1 = Conv2D(16, (3, 3), strides=(1, 1), activation='relu')\n",
    "        self.mpool_layer1 = MaxPooling2D(pool_size=(2, 2))\n",
    "        self.conv2D_layer2 = Conv2D(16, (3, 3), strides=(1, 1), activation='relu')\n",
    "        self.mpool_layer2 = MaxPooling2D(pool_size=(2, 2))\n",
    "        self.dense = Dense(1, activation='sigmoid')\n",
    "        self.pool = GlobalAveragePooling1D()\n",
    "        self.dropout = Dropout(rate=0.5)\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        inp_preprocessed = self.conv2D_layer1(inputs)\n",
    "        inp_preprocessed = self.mpool_layer1(inp_preprocessed)\n",
    "        inp_preprocessed = self.conv2D_layer2(inp_preprocessed)\n",
    "        inp_preprocessed = self.mpool_layer2(inp_preprocessed)\n",
    "\n",
    "        patches = tf.image.extract_patches(\n",
    "            images=inp_preprocessed,\n",
    "            sizes=[1, 16, 16, 1],\n",
    "            strides=[1, 16, 16, 1],\n",
    "            rates=[1, 1, 1, 1],\n",
    "            padding='SAME'\n",
    "        )\n",
    "        batch_size = tf.shape(patches)[0]\n",
    "        patches = tf.reshape(patches, [batch_size, -1, tf.shape(patches)[-1]])\n",
    "\n",
    "        x = self.patch_embed(patches)\n",
    "        for transformer_layer in self.transformer_layers:\n",
    "            x = transformer_layer(x, training=training)\n",
    "\n",
    "        x = self.dropout(x, training=training)\n",
    "        x = self.pool(x)\n",
    "        return self.dense(x)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            \"num_patches\": self.num_patches,\n",
    "            \"num_heads\": self.num_heads,\n",
    "            \"embed_dim\": self.embed_dim,\n",
    "            \"ffn_dim\": self.ffn_dim,\n",
    "            \"num_layers\": self.num_layers,\n",
    "            \"num_classes\": self.num_classes\n",
    "        })\n",
    "        return config\n",
    "\n",
    "    @classmethod\n",
    "    def from_config(cls, config):\n",
    "        return cls(**config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d9332501-790b-4215-90fe-30e0d352436a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "model=VisionImageTransformer(\n",
    "    num_patches=196,\n",
    "    embed_dim=100,\n",
    "    num_heads=4,\n",
    "    ffn_dim=130,\n",
    "    num_layers=4,\n",
    "    num_classes=2\n",
    ")\n",
    "model.compile(optimizer='Adam',loss='binary_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e0f1be1e-af3b-4ccd-b12d-39795b34fc81",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rajveer Gupta\\anaconda3\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rajveer Gupta\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\layer.py:421: UserWarning: `build()` was called on layer 'vision_image_transformer', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m263s\u001b[0m 1s/step - accuracy: 0.7225 - loss: 0.6169 - val_accuracy: 0.6240 - val_loss: 0.9060\n",
      "Epoch 2/30\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m153s\u001b[0m 819ms/step - accuracy: 0.7694 - loss: 0.4663 - val_accuracy: 0.6544 - val_loss: 0.6981\n",
      "Epoch 3/30\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 949ms/step - accuracy: 0.8211 - loss: 0.3715 - val_accuracy: 0.6608 - val_loss: 0.6763\n",
      "Epoch 4/30\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1114s\u001b[0m 7s/step - accuracy: 0.8421 - loss: 0.3289 - val_accuracy: 0.8000 - val_loss: 0.4773\n",
      "Epoch 5/30\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11354s\u001b[0m 70s/step - accuracy: 0.8533 - loss: 0.3170 - val_accuracy: 0.7568 - val_loss: 0.4606\n",
      "Epoch 6/30\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m217s\u001b[0m 1s/step - accuracy: 0.8613 - loss: 0.2925 - val_accuracy: 0.7920 - val_loss: 0.4704\n",
      "Epoch 7/30\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m239s\u001b[0m 1s/step - accuracy: 0.8805 - loss: 0.2814 - val_accuracy: 0.8224 - val_loss: 0.4055\n",
      "Epoch 8/30\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m715s\u001b[0m 4s/step - accuracy: 0.8832 - loss: 0.2710 - val_accuracy: 0.7968 - val_loss: 0.4649\n",
      "Epoch 9/30\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m235s\u001b[0m 1s/step - accuracy: 0.8722 - loss: 0.2891 - val_accuracy: 0.6752 - val_loss: 0.5909\n",
      "Epoch 10/30\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m255s\u001b[0m 1s/step - accuracy: 0.7673 - loss: 0.4190 - val_accuracy: 0.6352 - val_loss: 0.7113\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1e2a281fb30>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "early_stop=EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=3,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "model.fit(train_generator,validation_data=test_generator,epochs=30,callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8e6ac300-a943-4419-8025-512c2db97f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('Pneumonia_Detector_Model_2.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6d85bf26-9497-4a4e-9c65-2ede3ef42cd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 452ms/step - accuracy: 0.7500 - loss: 0.7044\n"
     ]
    }
   ],
   "source": [
    "accuracy=model.evaluate(valid_generator)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
